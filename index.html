<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/website2/_next/static/media/569ce4b8f30dc480-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/website2/_next/static/media/93f479601ee12b01-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/website2/_next/static/css/126e234a0c6c6bde.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/website2/_next/static/chunks/webpack-b970bf36b1c0455a.js"/><script src="/website2/_next/static/chunks/4bd1b696-52a6696c08e3276c.js" async=""></script><script src="/website2/_next/static/chunks/684-4098f11d7bbc8465.js" async=""></script><script src="/website2/_next/static/chunks/main-app-be7e1ccb34745cfc.js" async=""></script><script src="/website2/_next/static/chunks/573-18a4668a89e1ab7a.js" async=""></script><script src="/website2/_next/static/chunks/app/page-61e7e425093d3a52.js" async=""></script><meta name="next-size-adjust" content=""/><title>GenHRL</title><meta name="description" content="Generative Hierarchical Reinforcement Learning"/><link rel="icon" href="/website2/favicon.ico" type="image/x-icon" sizes="16x16"/><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="/website2/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__variable_926cff __variable_470fb6 antialiased"><main class="container mx-auto p-4"><header class="my-6 text-center"><h1 class="text-4xl font-bold">GenHRL: Generative Hierarchical Reinforcement Learning</h1><p class="text-lg text-gray-700 mt-2">Authors Anonymous</p><div class="mt-6 max-w-3xl mx-auto text-left"><h2 class="text-2xl font-semibold mb-2 text-center">Abstract</h2><p class="text-gray-700 leading-relaxed">Defining effective multi-level skill hierarchies and their corresponding learning objectives is a core challenge in robotics and reinforcement learning. Large Language Models (LLMs) offer powerful new capabilities for tackling this challenge through automated generation and reasoning. This paper introduces GenHRL, an LLM-driven framework that automates the pipeline from high-level natural language task descriptions to learned hierarchical skills. GenHRL autonomously generates: (1) task-specific simulation environments, (2) multi-level skill decompositions, and (3) executable code defining intrinsic reward and termination functions for each skill. This automation avoids the need for manual reward engineering, predefined skill sets, offline datasets, and enables end-to-end hierarchical policy learning via standard reinforcement learning algorithms. Empirical evaluations on complex robotic humanoid simulation tasks demonstrate that GenHRL significantly enhances learning efficiency and final performance compared to non-hierarchical baselines.</p><div class="mt-4 text-center"><a href="https://openreview.net/forum?id=vPwAh0eL0D&amp;referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3Drobot-learning.org%2FCoRL%2F2025%2FConference%2FAuthors%23your-submissions)" target="https://openreview.net/forum?id=vPwAh0eL0D&amp;referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3Drobot-learning.org%2FCoRL%2F2025%2FConference%2FAuthors%23your-submissions)" rel="noopener noreferrer" class="inline-block bg-blue-500 hover:bg-blue-700 text-white font-bold py-2 px-4 rounded transition-colors">View on OpenReview</a></div></div><div class="my-8 max-w-4xl mx-auto"><h2 class="text-2xl font-semibold mb-4 text-center">Method Overview</h2><div class="w-full"><img alt="Method Diagram" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="h-auto w-full max-w-2xl mx-auto block" style="color:transparent" src="/website2/method_drawing.svg"/></div><div class="mt-4 text-left"><h3 class="text-xl font-semibold mb-2">Method Description:</h3><p class="text-gray-700 leading-relaxed">Our GenHRL system employs Large Language Models (LLMs) to automatically construct complex robot skills from simple language instructions. The process, illustrated above, unfolds in three main stages:</p><ul class="list-disc list-outside text-gray-700 leading-relaxed ml-5 mt-2"><li class="mb-2"><strong>Stage 1: Task Interpretation and Decomposition.</strong> The user provides a task description. The LLM then interprets this, designs a suitable simulation environment, and breaks the task down into a multi-level hierarchy of described skills.</li><li class="mb-2"><strong>Stage 2: Code Generation.</strong> The LLM translates these skill descriptions into executable code that defines the goals (rewards) and completion rules (terminations) for learning each skill. This generated code can be optionally checked by a human.</li><li class="mb-2"><strong>Stage 3: Hierarchical Reinforcement Learning.</strong> GenHRL utilizes this generated environment and code to automatically train policies for the entire skill hierarchy using reinforcement learning, ultimately resulting in an agent capable of performing the complex task.</li></ul></div></div><div class="mt-8 max-w-4xl mx-auto text-left"><h3 class="text-xl font-semibold mb-2">Demonstration Context:</h3><p class="text-gray-700 leading-relaxed mb-2">Below, we showcase the GenHRL system in action. For this demonstration, GenHRL was provided with the following high-level task description:</p><div class="bg-gray-100 border border-gray-300 p-3 rounded-md my-3 shadow-sm"><em class="text-gray-700 leading-relaxed">&quot;The robot should jump over a low wall, push a large sphere into a high wall to knock it down and pass over it. The robot should then walk to a small sphere and kick it past a block. Finally the robot should walk to the block and jump onto it.&quot;</em></div><p class="text-gray-700 leading-relaxed mb-2">From this instruction, the system first generates the corresponding simulation environment, including the layout of all necessary objects. It then automatically designs the multi-level skill hierarchy that you can explore interactively below.</p><p class="text-gray-700 leading-relaxed mb-2">Furthermore, GenHRL generates the underlying executable code for each skill, including the reward functions that guide learning and the success termination conditions that define task completion. Each higher-level skill in the hierarchy is composed of and utilizes the skills immediately below it to achieve its objective.</p><p class="text-gray-700 leading-relaxed">To explore the generated hierarchy, simply click on any skill box. This will reveal tabs for the <strong>Video Demo</strong>, which shows a successfully trained policy for that skill, as well as the <strong>Reward Code</strong> and <strong>Success Code</strong> generated by the LLM.</p></div><div class="text-center"><p class="text-xl text-gray-600 mt-8">----------------------------------------------------------</p></div></header><div class="p-4"><h1 class="text-2xl font-bold mb-4">Interactive Skill Hierarchy</h1><div class="ml-4 my-2"><div class="p-2 rounded bg-blue-700 hover:bg-blue-800 text-white border border-gray-400 flex items-center cursor-pointer" role="button" tabindex="0"><span class="mr-2 p-1 rounded">▼</span><span class="flex-grow">Obstacle Course<!-- --> (Level <!-- -->3<!-- -->)</span></div><div class="mt-1 border border-gray-300 rounded bg-gray-50 shadow-sm"><div class="flex border-b border-gray-300 bg-gray-100 rounded-t-md"><button class="px-3 py-1 text-base rounded-t-md cursor-pointer transition-colors bg-gray-200 font-semibold">Video Demo</button><button class="px-3 py-1 text-base rounded-t-md cursor-pointer transition-colors bg-gray-100 hover:bg-gray-200">Reward Code</button><button class="px-3 py-1 text-base rounded-t-md cursor-pointer transition-colors bg-gray-100 hover:bg-gray-200">Success Code</button></div><div class="p-2"><div><video controls="" width="100%" class="w-4/5 mx-auto rounded"><source src="/website2/videos/ZeroShotObstacleCourse.mp4" type="video/mp4"/>Your browser does not support the video tag.</video></div></div></div><div class="ml-4 border-l-2 border-gray-300 pl-2"><div class="ml-4 my-2"><div class="p-2 rounded bg-blue-500 hover:bg-blue-600 text-white border border-gray-400 flex items-center cursor-pointer" role="button" tabindex="0"><span class="mr-2 p-1 rounded">▼</span><span class="flex-grow">JumpOverLowWall<!-- --> (Level <!-- -->2<!-- -->)</span><span class="ml-auto text-xs italic opacity-75 px-2">Click for details</span></div><div class="ml-4 border-l-2 border-gray-300 pl-2"><div class="ml-4 my-2"><div class="p-2 rounded bg-blue-300 hover:bg-blue-400 text-gray-800 border border-gray-400 flex items-center cursor-pointer" role="button" tabindex="0"><span class="flex-grow">WalkToLowWall<!-- --> (Level <!-- -->1<!-- -->)</span><span class="ml-auto text-xs italic opacity-75 px-2">Click for details</span></div></div><div class="ml-4 my-2"><div class="p-2 rounded bg-blue-300 hover:bg-blue-400 text-gray-800 border border-gray-400 flex items-center cursor-pointer" role="button" tabindex="0"><span class="flex-grow">PrepareForJumpOverLowWall<!-- --> (Level <!-- -->1<!-- -->)</span><span class="ml-auto text-xs italic opacity-75 px-2">Click for details</span></div></div><div class="ml-4 my-2"><div class="p-2 rounded bg-blue-300 hover:bg-blue-400 text-gray-800 border border-gray-400 flex items-center cursor-pointer" role="button" tabindex="0"><span class="flex-grow">ExecuteJumpOverLowWall<!-- --> (Level <!-- -->1<!-- -->)</span><span class="ml-auto text-xs italic opacity-75 px-2">Click for details</span></div></div><div class="ml-4 my-2"><div class="p-2 rounded bg-blue-300 hover:bg-blue-400 text-gray-800 border border-gray-400 flex items-center cursor-pointer" role="button" tabindex="0"><span class="flex-grow">LandStablyAfterLowWall<!-- --> (Level <!-- -->1<!-- -->)</span><span class="ml-auto text-xs italic opacity-75 px-2">Click for details</span></div></div></div></div><div class="ml-4 my-2"><div class="p-2 rounded bg-blue-500 hover:bg-blue-600 text-white border border-gray-400 flex items-center cursor-pointer" role="button" tabindex="0"><span class="mr-2 p-1 rounded">▼</span><span class="flex-grow">PushLargeSphereToHighWall<!-- --> (Level <!-- -->2<!-- -->)</span><span class="ml-auto text-xs italic opacity-75 px-2">Click for details</span></div><div class="ml-4 border-l-2 border-gray-300 pl-2"><div class="ml-4 my-2"><div class="p-2 rounded bg-blue-300 hover:bg-blue-400 text-gray-800 border border-gray-400 flex items-center cursor-pointer" role="button" tabindex="0"><span class="flex-grow">WalkToLargeSphere<!-- --> (Level <!-- -->1<!-- -->)</span><span class="ml-auto text-xs italic opacity-75 px-2">Click for details</span></div></div><div class="ml-4 my-2"><div class="p-2 rounded bg-blue-300 hover:bg-blue-400 text-gray-800 border border-gray-400 flex items-center cursor-pointer" role="button" tabindex="0"><span class="flex-grow">PositionHandsForPushLargeSphere<!-- --> (Level <!-- -->1<!-- -->)</span><span class="ml-auto text-xs italic opacity-75 px-2">Click for details</span></div></div><div class="ml-4 my-2"><div class="p-2 rounded bg-blue-300 hover:bg-blue-400 text-gray-800 border border-gray-400 flex items-center cursor-pointer" role="button" tabindex="0"><span class="flex-grow">PushLargeSphereForward<!-- --> (Level <!-- -->1<!-- -->)</span><span class="ml-auto text-xs italic opacity-75 px-2">Click for details</span></div></div><div class="ml-4 my-2"><div class="p-2 rounded bg-blue-300 hover:bg-blue-400 text-gray-800 border border-gray-400 flex items-center cursor-pointer" role="button" tabindex="0"><span class="flex-grow">EnsureHighWallFalls<!-- --> (Level <!-- -->1<!-- -->)</span><span class="ml-auto text-xs italic opacity-75 px-2">Click for details</span></div></div></div></div><div class="ml-4 my-2"><div class="p-2 rounded bg-blue-500 hover:bg-blue-600 text-white border border-gray-400 flex items-center cursor-pointer" role="button" tabindex="0"><span class="mr-2 p-1 rounded">▼</span><span class="flex-grow">KickSmallSpherePastBlock<!-- --> (Level <!-- -->2<!-- -->)</span><span class="ml-auto text-xs italic opacity-75 px-2">Click for details</span></div><div class="ml-4 border-l-2 border-gray-300 pl-2"><div class="ml-4 my-2"><div class="p-2 rounded bg-blue-300 hover:bg-blue-400 text-gray-800 border border-gray-400 flex items-center cursor-pointer" role="button" tabindex="0"><span class="flex-grow">WalkToSmallSphere<!-- --> (Level <!-- -->1<!-- -->)</span><span class="ml-auto text-xs italic opacity-75 px-2">Click for details</span></div></div><div class="ml-4 my-2"><div class="p-2 rounded bg-blue-300 hover:bg-blue-400 text-gray-800 border border-gray-400 flex items-center cursor-pointer" role="button" tabindex="0"><span class="flex-grow">ExecuteKickSmallSphereForward<!-- --> (Level <!-- -->1<!-- -->)</span><span class="ml-auto text-xs italic opacity-75 px-2">Click for details</span></div></div></div></div><div class="ml-4 my-2"><div class="p-2 rounded bg-blue-500 hover:bg-blue-600 text-white border border-gray-400 flex items-center cursor-pointer" role="button" tabindex="0"><span class="mr-2 p-1 rounded">▼</span><span class="flex-grow">JumpOntoBlock<!-- --> (Level <!-- -->2<!-- -->)</span><span class="ml-auto text-xs italic opacity-75 px-2">Click for details</span></div><div class="ml-4 border-l-2 border-gray-300 pl-2"><div class="ml-4 my-2"><div class="p-2 rounded bg-blue-300 hover:bg-blue-400 text-gray-800 border border-gray-400 flex items-center cursor-pointer" role="button" tabindex="0"><span class="flex-grow">WalkToBlock<!-- --> (Level <!-- -->1<!-- -->)</span><span class="ml-auto text-xs italic opacity-75 px-2">Click for details</span></div></div><div class="ml-4 my-2"><div class="p-2 rounded bg-blue-300 hover:bg-blue-400 text-gray-800 border border-gray-400 flex items-center cursor-pointer" role="button" tabindex="0"><span class="flex-grow">PrepareForJumpOntoBlock<!-- --> (Level <!-- -->1<!-- -->)</span><span class="ml-auto text-xs italic opacity-75 px-2">Click for details</span></div></div><div class="ml-4 my-2"><div class="p-2 rounded bg-blue-300 hover:bg-blue-400 text-gray-800 border border-gray-400 flex items-center cursor-pointer" role="button" tabindex="0"><span class="flex-grow">ExecuteJumpOntoBlock<!-- --> (Level <!-- -->1<!-- -->)</span><span class="ml-auto text-xs italic opacity-75 px-2">Click for details</span></div></div><div class="ml-4 my-2"><div class="p-2 rounded bg-blue-300 hover:bg-blue-400 text-gray-800 border border-gray-400 flex items-center cursor-pointer" role="button" tabindex="0"><span class="flex-grow">StabilizeOnBlockTop<!-- --> (Level <!-- -->1<!-- -->)</span><span class="ml-auto text-xs italic opacity-75 px-2">Click for details</span></div></div></div></div></div></div></div><footer class="mt-8 text-center text-gray-500"><p>Level 0 skills are Primitive Actions and are implicitly part of Level 1 skills.</p></footer></main><!--$--><!--/$--><!--$--><!--/$--><script src="/website2/_next/static/chunks/webpack-b970bf36b1c0455a.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[7555,[],\"\"]\n3:I[1295,[],\"\"]\n5:I[3063,[\"573\",\"static/chunks/573-18a4668a89e1ab7a.js\",\"974\",\"static/chunks/app/page-61e7e425093d3a52.js\"],\"Image\"]\n6:I[3169,[\"573\",\"static/chunks/573-18a4668a89e1ab7a.js\",\"974\",\"static/chunks/app/page-61e7e425093d3a52.js\"],\"default\"]\n7:I[9665,[],\"MetadataBoundary\"]\n9:I[9665,[],\"OutletBoundary\"]\nc:I[4911,[],\"AsyncMetadataOutlet\"]\ne:I[9665,[],\"ViewportBoundary\"]\n10:I[6614,[],\"\"]\n:HL[\"/website2/_next/static/media/569ce4b8f30dc480-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/website2/_next/static/media/93f479601ee12b01-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/website2/_next/static/css/126e234a0c6c6bde.css\",\"style\"]\n4:T41e,Defining effective multi-level skill hierarchies and their corresponding learning objectives is a core challenge in robotics and reinforcement learning. Large Language Models (LLMs) offer powerful new capabilities for tackling this challenge through automated generation and reasoning. This paper introduces GenHRL, an LLM-driven framework that automates the pipeline from high-level natural language task descriptions to learned hierarchical skills. GenHRL autonomously generates: (1) task-specific simulation environments, (2) multi-level skill decompositions, and (3) executable code defining intrinsic reward and termination functions for each skill. This automation avoids the need for manual reward engineering, predefined skill sets, offline datasets, and enables end-to-end hierarchical policy learning via standard reinforcement learning algorithms. Empirical evaluations on complex robotic humanoid simulation tasks demonstrate that GenHRL significantly enhances learning efficiency and final performance compared to non-hierarchical baselines."])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"EYxcJe-JLirmvhapgSEOI\",\"p\":\"/website2\",\"c\":[\"\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/website2/_next/static/css/126e234a0c6c6bde.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"__variable_926cff __variable_470fb6 antialiased\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"main\",null,{\"className\":\"container mx-auto p-4\",\"children\":[[\"$\",\"header\",null,{\"className\":\"my-6 text-center\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-4xl font-bold\",\"children\":\"GenHRL: Generative Hierarchical Reinforcement Learning\"}],[\"$\",\"p\",null,{\"className\":\"text-lg text-gray-700 mt-2\",\"children\":\"Authors Anonymous\"}],[\"$\",\"div\",null,{\"className\":\"mt-6 max-w-3xl mx-auto text-left\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-2xl font-semibold mb-2 text-center\",\"children\":\"Abstract\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed\",\"children\":\"$4\"}],[\"$\",\"div\",null,{\"className\":\"mt-4 text-center\",\"children\":[\"$\",\"a\",null,{\"href\":\"https://openreview.net/forum?id=vPwAh0eL0D\u0026referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3Drobot-learning.org%2FCoRL%2F2025%2FConference%2FAuthors%23your-submissions)\",\"target\":\"https://openreview.net/forum?id=vPwAh0eL0D\u0026referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3Drobot-learning.org%2FCoRL%2F2025%2FConference%2FAuthors%23your-submissions)\",\"rel\":\"noopener noreferrer\",\"className\":\"inline-block bg-blue-500 hover:bg-blue-700 text-white font-bold py-2 px-4 rounded transition-colors\",\"children\":\"View on OpenReview\"}]}]]}],[\"$\",\"div\",null,{\"className\":\"my-8 max-w-4xl mx-auto\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-2xl font-semibold mb-4 text-center\",\"children\":\"Method Overview\"}],[\"$\",\"div\",null,{\"className\":\"w-full\",\"children\":[\"$\",\"$L5\",null,{\"src\":\"/website2/method_drawing.svg\",\"alt\":\"Method Diagram\",\"width\":800,\"height\":600,\"className\":\"h-auto w-full max-w-2xl mx-auto block\"}]}],[\"$\",\"div\",null,{\"className\":\"mt-4 text-left\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-xl font-semibold mb-2\",\"children\":\"Method Description:\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed\",\"children\":\"Our GenHRL system employs Large Language Models (LLMs) to automatically construct complex robot skills from simple language instructions. The process, illustrated above, unfolds in three main stages:\"}],[\"$\",\"ul\",null,{\"className\":\"list-disc list-outside text-gray-700 leading-relaxed ml-5 mt-2\",\"children\":[[\"$\",\"li\",null,{\"className\":\"mb-2\",\"children\":[[\"$\",\"strong\",null,{\"children\":\"Stage 1: Task Interpretation and Decomposition.\"}],\" The user provides a task description. The LLM then interprets this, designs a suitable simulation environment, and breaks the task down into a multi-level hierarchy of described skills.\"]}],[\"$\",\"li\",null,{\"className\":\"mb-2\",\"children\":[[\"$\",\"strong\",null,{\"children\":\"Stage 2: Code Generation.\"}],\" The LLM translates these skill descriptions into executable code that defines the goals (rewards) and completion rules (terminations) for learning each skill. This generated code can be optionally checked by a human.\"]}],[\"$\",\"li\",null,{\"className\":\"mb-2\",\"children\":[[\"$\",\"strong\",null,{\"children\":\"Stage 3: Hierarchical Reinforcement Learning.\"}],\" GenHRL utilizes this generated environment and code to automatically train policies for the entire skill hierarchy using reinforcement learning, ultimately resulting in an agent capable of performing the complex task.\"]}]]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"mt-8 max-w-4xl mx-auto text-left\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-xl font-semibold mb-2\",\"children\":\"Demonstration Context:\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-2\",\"children\":\"Below, we showcase the GenHRL system in action. For this demonstration, GenHRL was provided with the following high-level task description:\"}],[\"$\",\"div\",null,{\"className\":\"bg-gray-100 border border-gray-300 p-3 rounded-md my-3 shadow-sm\",\"children\":[\"$\",\"em\",null,{\"className\":\"text-gray-700 leading-relaxed\",\"children\":\"\\\"The robot should jump over a low wall, push a large sphere into a high wall to knock it down and pass over it. The robot should then walk to a small sphere and kick it past a block. Finally the robot should walk to the block and jump onto it.\\\"\"}]}],[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-2\",\"children\":\"From this instruction, the system first generates the corresponding simulation environment, including the layout of all necessary objects. It then automatically designs the multi-level skill hierarchy that you can explore interactively below.\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-2\",\"children\":\"Furthermore, GenHRL generates the underlying executable code for each skill, including the reward functions that guide learning and the success termination conditions that define task completion. Each higher-level skill in the hierarchy is composed of and utilizes the skills immediately below it to achieve its objective.\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed\",\"children\":[\"To explore the generated hierarchy, simply click on any skill box. This will reveal tabs for the \",[\"$\",\"strong\",null,{\"children\":\"Video Demo\"}],\", which shows a successfully trained policy for that skill, as well as the \",[\"$\",\"strong\",null,{\"children\":\"Reward Code\"}],\" and \",[\"$\",\"strong\",null,{\"children\":\"Success Code\"}],\" generated by the LLM.\"]}]]}],[\"$\",\"div\",null,{\"className\":\"text-center\",\"children\":[\"$\",\"p\",null,{\"className\":\"text-xl text-gray-600 mt-8\",\"children\":\"----------------------------------------------------------\"}]}]]}],[\"$\",\"$L6\",null,{}],[\"$\",\"footer\",null,{\"className\":\"mt-8 text-center text-gray-500\",\"children\":[\"$\",\"p\",null,{\"children\":\"Level 0 skills are Primitive Actions and are implicitly part of Level 1 skills.\"}]}]]}],[\"$\",\"$L7\",null,{\"children\":\"$L8\"}],null,[\"$\",\"$L9\",null,{\"children\":[\"$La\",\"$Lb\",[\"$\",\"$Lc\",null,{\"promise\":\"$@d\"}]]}]]}],{},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"C8kuj5gf3veHxew-PdQNG\",{\"children\":[[\"$\",\"$Le\",null,{\"children\":\"$Lf\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],null]}],false]],\"m\":\"$undefined\",\"G\":[\"$10\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"11:\"$Sreact.suspense\"\n12:I[4911,[],\"AsyncMetadata\"]\n8:[\"$\",\"$11\",null,{\"fallback\":null,\"children\":[\"$\",\"$L12\",null,{\"promise\":\"$@13\"}]}]\n"])</script><script>self.__next_f.push([1,"b:null\n"])</script><script>self.__next_f.push([1,"f:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\na:null\n"])</script><script>self.__next_f.push([1,"13:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"GenHRL\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Generative Hierarchical Reinforcement Learning\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/website2/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]],\"error\":null,\"digest\":\"$undefined\"}\nd:{\"metadata\":\"$13:metadata\",\"error\":null,\"digest\":\"$undefined\"}\n"])</script></body></html>